# 9.6 Sales Rank

## Problem Description

A large eCommerce company wishes to list the best-selling products, overall and by category. For example, one product
might be the #1056th best-selling product overall but the #13th best-selling product under "Sports Equipment" and the
#24th best-selling product under "Safety." Describe how you would design this system.

## Solution

Designing a system to rank **best-selling products overall and by category** for a large eCommerce company requires a scalable, efficient, and real-time capable architecture. Here's the system design:

---

### **1. System Requirements**
#### **Functional Requirements**:
1. Provide **overall rankings** of products based on sales.
2. Provide **category-specific rankings** (e.g., "Sports Equipment" or "Safety").
3. Support queries like:
   - "What are the top 10 best-selling products in Sports Equipment?"
   - "What is the rank of product X overall and in a category?"
4. Rankings should update in near-real-time as sales data is received.

#### **Non-Functional Requirements**:
1. Scalability to handle millions of products and thousands of categories.
2. Low latency for read and write operations.
3. Fault tolerance and high availability.

---

### **2. Key Challenges**
1. **Dynamic Updates**: Sales data streams in continuously, requiring frequent ranking updates.
2. **Category Overlap**: A product can belong to multiple categories (e.g., a safety helmet might be in both "Safety" and "Sports Equipment").
3. **Large Scale**: Managing rankings for millions of products across thousands of categories.

---

### **3. High-Level Architecture**

#### **A. Data Sources**
- **Sales Event Stream**:
  - Record real-time sales transactions (e.g., product ID, quantity sold, timestamp, category).
  - Use a message broker like **Kafka** or **Kinesis** for streaming events.

#### **B. Processing Layer**
1. **Stream Processing**:
   - Aggregate sales data in real time.
   - Tools: **Apache Flink**, **Apache Spark Streaming**, or **AWS Lambda**.
   - For each sales event:
     - Update overall sales count for the product.
     - Update sales count for the product in all its categories.

2. **Batch Processing**:
   - Periodically recompute rankings to ensure accuracy and resolve any inconsistencies.
   - Tools: **Apache Hadoop** or **Apache Spark**.

#### **C. Storage Layer**
1. **Sales Aggregation**:
   - Use a **distributed database** like **Cassandra** or **DynamoDB** to store:
     - Product sales count (overall).
     - Sales count by category.

2. **Ranking Data**:
   - Use a **sorted data structure** (e.g., Redis Sorted Sets) to maintain rankings:
     - One sorted set for overall rankings.
     - One sorted set per category.

#### **D. Query Layer**
- API endpoints to:
  - Fetch top N products overall or by category.
  - Fetch rank and sales count for a specific product.

#### **E. Frontend Layer**
- A user-friendly interface for displaying rankings and product details.

---

### **4. Detailed Design**

#### **A. Real-Time Sales Updates**
- Each sales event updates the product’s sales count in the database.
- **Stream Processor Workflow**:
  1. Read sales events from Kafka.
  2. Update product sales count in the database.
  3. Update rankings in Redis Sorted Sets:
     - Increment the product’s score (sales count).
     - Update overall and category-specific rankings.

#### **B. Ranking Data Structure**
- **Redis Sorted Sets**:
  - Use Redis to maintain rankings:
    - Key: `OverallRanking` for global rankings.
    - Key: `Category:<CategoryName>` for category rankings.
    - Member: `ProductID`.
    - Score: `SalesCount`.

#### **C. Handling Category Overlap**
- When a product belongs to multiple categories:
  - Update sales counts and rankings in all relevant category-specific sorted sets.

#### **D. Query Optimization**
- For queries like "Top N products in a category":
  - Use `ZRANGE` command in Redis for efficient retrieval.
- For queries like "Rank of a specific product":
  - Use `ZRANK` command in Redis to fetch rank in O(log N) time.

#### **E. Periodic Batch Processing**
- To ensure consistency, periodically recompute rankings using a batch pipeline:
  1. Aggregate sales counts from raw sales logs.
  2. Rebuild sorted sets in Redis.

---

### **5. Scalability Considerations**

#### **A. Data Partitioning**
- Partition the sales database and ranking data:
  - By product ID for overall sales.
  - By category for category-specific rankings.

#### **B. Distributed Processing**
- Use a distributed stream processor to handle high event throughput.
- Scale horizontally by adding more nodes to the stream processing cluster.

#### **C. Redis Clustering**
- Use Redis clusters to distribute sorted sets across multiple nodes for scalability.

#### **D. Caching Frequently Accessed Queries**
- Cache popular queries (e.g., top 10 products overall) in memory for faster access.

---

### **6. Failure Handling**
1. **Event Duplication**:
   - Use unique IDs for sales events and idempotent updates to avoid double-counting.
2. **Redis Failures**:
   - Use Redis replication and failover mechanisms (e.g., Redis Sentinel).
3. **Database Failures**:
   - Use replication and backups for the distributed database.

---

### **7. Example Workflow**
#### **Sales Event**:
1. A user purchases a helmet (`ProductID: 123`) in the "Sports Equipment" and "Safety" categories.
2. Event `{ProductID: 123, Quantity: 2, Categories: ["Sports Equipment", "Safety"]}` is sent to Kafka.
3. Stream processor reads the event and:
   - Updates the sales count for `ProductID: 123` in the database.
   - Increments the score of `ProductID: 123` in:
     - `OverallRanking` in Redis.
     - `Category:Sports Equipment` and `Category:Safety` in Redis.

#### **Query**:
- A user queries "Top 10 products in Sports Equipment":
  1. API retrieves data from Redis using `ZRANGE Category:Sports Equipment 0 9 WITHSCORES`.
  2. The result is returned in milliseconds.

---

### **8. Trade-Offs**

| **Aspect**              | **Choice**                  | **Pros**                                           | **Cons**                                              |
|-------------------------|-----------------------------|---------------------------------------------------|------------------------------------------------------|
| **Real-Time Updates**   | Redis Sorted Sets           | Fast, efficient ranking updates.                  | Memory-intensive, not suitable for very large data. |
| **Batch Consistency**   | Periodic recomputation      | Ensures accuracy across all rankings.             | Introduces latency for updates.                     |
| **Scalability**         | Distributed DB + Redis      | Scales horizontally for high throughput.          | Complexity in managing distributed systems.         |

---

### **9. Summary**
- **Real-Time Ranking**: Use Redis Sorted Sets for low-latency updates and queries.
- **Persistent Storage**: Use a distributed database to store aggregated sales counts.
- **Stream Processing**: Real-time updates with Apache Flink or Spark Streaming.
- **Batch Reprocessing**: Periodic recomputation for accuracy.

This design ensures the system is scalable, consistent, and performant, meeting the needs of a large eCommerce platform.